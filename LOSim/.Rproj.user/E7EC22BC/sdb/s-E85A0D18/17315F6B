{
    "collab_server" : "",
    "contents" : "################################################################################\n#SH25-09-2016                                                                  #\n# re-fit parameters                                                            #\n#                                                                              #\n################################################################################\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n#set seed\nset.seed(25012017)\n\n# load packages\nlibrary(LOSim)\nlibrary(sp)\nlibrary(raster)\nlibrary(ranger)\nlibrary(foreach)\nlibrary(doSNOW)\n\n# source functions\nsource(\"../code/CalibDataPrep.r\")\nsource(\"../code/sumStats.r\")\nsource(\"../code/getSumStats.r\")\nsource(\"../code/createPriors.r\")\nsource(\"../code/runABC.r\")\nsource(\"../code/ABCsummaryChoice.r\")\nsource(\"../code/plotSummariesCorrelation.r\")\nsource(\"../code/ABCgetEstimate.r\")\nsource(\"../code/mergeLOSim.r\")\n\n# load rcpp function to calculate distance between observed and simulated data\nRcpp::sourceCpp(\"../code/c++/distanceObservedSimulated.cpp\")\n\n# individual to use\ngp <- 69\n\n# if predictions should consecutively be included as predictors\npredictionPredictor <- TRUE\nparallel <- TRUE\nregr.adj <- TRUE\ncomp.MAP <- TRUE\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n# in sample refitting                                                         ##\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n\n# load simulations + remove all but for the first individual\nload(\"../data/summaries.RData\")\nsumOut <- summaries; rm(summaries)\n# upper and lower bounds for truncated multivariate normal distribution\nlbounds <- c(0.1, 0.1, 0.1, 0.01)\nubounds <- c(5, 4, 3.5, 30)\nsumOut$summarySelection$simulation <- sumOut$summarySelection$simulation[[gp]]\nsumOut$summarySelection$observed <- sumOut$validity <- sumOut$observations <- NULL\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n\n# sample parameters from prior sample\nn = 500\ncutoff <- 0.1\nPwhich <- sample(which(rowSums(sapply(seq_along(sumOut$summarySelection$targetParameters),\n                                      function(x) sumOut$parameters[,sumOut$summarySelection$targetParameters[x]] > \n                                        (lbounds[x] + (ubounds[x]-lbounds[x])*cutoff) &\n                                        sumOut$parameters[,sumOut$summarySelection$targetParameters[x]] < \n                                        (ubounds[x] - (ubounds[x]-lbounds[x])*cutoff))) == 4),\n                 size = n)\n# Pwhich <- sample(NROW(sumOut$parameters), size = n)\nPReFit <- sumOut$parameters[Pwhich,]\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n\n# rejection sampling\nproportionFiltered <- 1/500\nnumberParametersFiltered <- ceiling(nrow(sumOut$parameters) * proportionFiltered)\n\ndistances <- filtered <- pMedian <- pQuantiles <- vector(\"list\", n)   \n\nfor(i in seq(n)){\n  \n  # standardise by range\n  reference <- unlist(diff(apply(sumOut$summarySelection$simulation[-Pwhich[i],], 2, range)))\n  \n  distances[[i]] <- dObsSim(simulated = as.matrix(sumOut$summarySelection$simulation[-Pwhich[i],]),\n                            observed = unlist(sumOut$summarySelection$simulation[Pwhich[i],]),\n                            reference = reference)\n  \n  # accepted indices\n  filtered_indices <- sort(distances[[i]], method = \"quick\",\n                           index.return = TRUE)$ix[1:numberParametersFiltered]\n  \n  filtered[[i]] <- sumOut$parameters[-Pwhich[i],][filtered_indices,\n                                                  sumOut$summarySelection$targetParameters]\n  \n  if(regr.adj){\n    # S_sim of accepted sample\n    filtered_ss <- sumOut$summarySelection$simulation[-Pwhich[i],][filtered_indices,]\n    for(c in seq(NCOL(filtered_ss))) # center around S_obs\n      filtered_ss[,c] <- filtered_ss[,c] - sumOut$summarySelection$simulation[Pwhich[i],c]\n    # post-sampling regression adjustment, multivariate linear model\n    psr.fm <- lm(as.formula(paste(\"filtered[[i]]~\",paste(colnames(filtered_ss), collapse = \"+\"))), \n                 data = filtered_ss)$coefficients[-1,] # remove intercept\n    # correct for epsilon != 0\n    filtered[[i]] <- sapply(seq(NCOL(filtered_ss)), \n                            function(x) filtered[[i]][,x] - rowSums(t(psr.fm[,x] * t(filtered_ss))))\n    # restrict corrections to prior bounds\n    filtered[[i]] <- sapply(seq(NCOL(filtered_ss)),\n                            function(x) ifelse(filtered[[i]][,x] < lbounds[x], lbounds[x], \n                                               ifelse(filtered[[i]][,x] > ubounds[x], ubounds[x], \n                                                      filtered[[i]][,x])))\n    colnames(filtered[[i]]) <- colnames(sumOut$parameters)[sumOut$summarySelection$targetParameters]\n  }\n  \n  pMedian[[i]] <- apply(filtered[[i]], 2, median)\n  pQuantiles[[i]] <- apply(filtered[[i]], 2, quantile, probs = c(0.025,0.975))\n}\n\nif(comp.MAP){\n  if(!parallel){\n    library(tmvtnorm)\n    pMAP <- vector(\"list\", n)\n    # progress bar\n    pb <- txtProgressBar(min = 0, max = n, style = 3)\n    for(i in seq.int(n)){\n      pMAP[[i]] <- mle.tmvnorm(filtered[[i]], method = \"L-BFGS-B\", \n                               lower.bounds = lbounds, \n                               upper.bounds = ubounds)@coef[1:NCOL(filtered[[i]])]\n      pMAP[[i]] <- ifelse(pMAP[[i]] < lbounds, lbounds,\n                          ifelse(pMAP[[i]] > ubounds, ubounds,\n                                 pMAP[[i]]))\n      names(pMAP[[i]]) <- colnames(sumOut$parameters)[sumOut$summarySelection$targetParameters]\n      # progress bar\n      setTxtProgressBar(pb, i)\n    }\n    close(pb)\n  }else{\n    # parallel execution\n    library(foreach)\n    # library(doParallel)\n    library(doSNOW)\n    \n    if(parallel == T | parallel == \"auto\"){\n      cores <- parallel::detectCores() - 1\n      message(\"parallel, set cores automatically to \", cores)\n    }else if (is.numeric(parallel)){\n      cores <- parallel\n      message(\"parallel, set number of cores manually to \", cores)\n    }else stop(\"wrong argument to parallel\")\n    \n    \n    cl <- parallel::makeCluster(cores)\n    doSNOW::registerDoSNOW(cl)\n    \n    # set up progress bar\n    pb <- txtProgressBar(min = 1, max = n, style = 3)\n    progress <- function(n) setTxtProgressBar(pb, n)\n    opts <- list(progress = progress)\n    \n    pMAP <- foreach::foreach(i = seq.int(n), \n                             .options.snow=opts, .packages = \"tmvtnorm\") %dopar% {\n                               maps <- mle.tmvnorm(filtered[[i]], method = \"L-BFGS-B\",\n                                                   lower.bounds = lbounds, \n                                                   upper.bounds = ubounds)@coef[1:NCOL(filtered[[i]])]\n                               maps <- ifelse(maps < lbounds, lbounds,\n                                              ifelse(maps > ubounds, ubounds,\n                                                     maps))\n                               names(maps) <- colnames(sumOut$parameters)[sumOut$summarySelection$targetParameters]\n                               maps\n                             }\n    \n    # free memory from workers\n    close(pb)\n    stopCluster(cl)\n  }\n}\n\n\nposteriorInS = NULL\nposteriorInS$parameters = filtered\nposteriorInS$median = pMedian\nif(comp.MAP) posteriorInS$MAP = pMAP\nposteriorInS$quantiles = pQuantiles\nposteriorInS$targetParameters = sumOut$summarySelection$targetParameters\nposteriorInS$proportion = proportionFiltered\n\n\n# save(posteriorInS, file = \"../data/posteriorInS_ParameterReFit.RData\")\n# load(\"../data/posteriorInS_ParameterReFit.RData\")\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n# out of sample refitting                                                     ##\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n\n# load/prepare model input   #\n#--------##--------##--------##--------##--------##--------##--------##--------#\n# load telemetry data\ncleaned <- read.csv(\"../data/natal_dispersal_cleaned.csv\",\n                    stringsAsFactors = FALSE)\n# date as POSIXct\ncleaned$date <- as.POSIXct(cleaned$date)\ncleaned$date <- lubridate::with_tz(cleaned$date, \"GMT\")\n# load IDs of training and validation set\nload(\"../data/trainTestIDs.RData\")\n\n\n#----------------------------------------------------#\n\n# classify dispersal locations # date of first outing (400m buffer)\nfirstOut <- 1:3\nfor(i in seq_along(unique(cleaned$id))){\n  idIndex <- which(cleaned$id == unique(cleaned$id)[i])\n  birthIndex <- idIndex[which.min(cleaned$date[cleaned$id == \n                                                 unique(cleaned$id)[i]])]\n  distToBL <- sapply(idIndex, function(x) \n    sqrt((cleaned$posX[x] - cleaned$posX[birthIndex])^2\n         + (cleaned$posY[x] - cleaned$posY[birthIndex])^2))\n  \n  search = TRUE\n  j = 1\n  while(search){\n    if(distToBL[j] > 400){\n      search = FALSE\n      firstOut[i] = idIndex[j]\n    }\n    j = j + 1\n  }\n} \n\nfirstOut <- cleaned[firstOut,]\n\n\n# select locations within dispersal period, i.e. \ndispersal <- cleaned[-c(1:NROW(cleaned)),]\nfor(x in unique(cleaned$id)){\n  subs <-  cleaned[cleaned$id == x \n                   & cleaned$date >= firstOut$date[firstOut$id == x] \n                   & cleaned$date <= (firstOut$date[firstOut$id == x] + 3600*24*60),]\n  dispersal <- rbind(dispersal, subs)\n}\nrm(search, x, j, i, idIndex, distToBL, birthIndex, subs)\n\n# # spatialpointsdataframe\ndispSpdf <- SpatialPointsDataFrame(coords = dispersal[,c(\"posX\",\"posY\")], \n                                   data = dispersal) \n# add correct projection: DHDN / Gauss-Kruger zone 3\nproj4string(dispSpdf) <- CRS(\"+init=epsg:31467\")\n\n#----------------------------------------------------#\n# get start points from dispersal data, i.e. first recorded locations in dispersal period\nstartIndex <- 1:3\nfor(i in seq_along(unique(dispSpdf$id))){\n  idIndex <- which(dispSpdf$id == unique(dispSpdf$id)[i])\n  startIndex[i] <- idIndex[which(dispSpdf$date[idIndex] == min(dispSpdf$date[idIndex]))]\n} \nstartPoints <- dispSpdf[startIndex, ]\n\n# telemetry data extent + 50 km buffer\ncalibrationExtent <- extent(startPoints) + rep(c(-50000,50000), 2)\n\n#----------------------------------------------------#\n# load habitat suitability\nhabitatSuitability <- raster(\"../envVars/envOnStudyExtent/habitatSuitabilityScaled.tif\")\n# crop habitat suitability map\nhabSuitCalib <- crop(habitatSuitability, calibrationExtent)\nhabSuitCalib[is.na(values(habSuitCalib))] <- 0 # set NAs to zero <- reflection\nHSvals <- as.matrix(habSuitCalib)\n# update calibrationExtent\ncalibrationExtent <- extent(habSuitCalib)\n\n#----------------------------------------------------#\n# priors for observation error\nAccuracy <- sapply(unique(dispSpdf$id), function(x) dispersal$accuracy[dispersal$id == x])\naccLookUp <- c(0,5,20,50,100,200)\nAccMetric <- sapply(unique(dispSpdf$id), function(x) accLookUp[Accuracy[[x]]+1])\nAccMetric <- unlist(AccMetric)\n\n#----------------------------------------------------#\n# prepare telemetry data\nrscRange = 200\ncalibrationData <- calibTransform(x = dispersal$posX, y = dispersal$posY,\n                                  date = dispersal$date, id = dispersal$id,\n                                  habitatSuitability = habSuitCalib, rscExtent = rscRange)\n\n# filter individuals with more than 50 recorded locations\nnRelocs <- sapply(seq_along(calibrationData), function(x) NROW(calibrationData[[x]]$data))\ncalibID <- names(calibrationData)[nRelocs  > 50 & names(calibrationData) %in% trainingID]\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n# simulate observed data for gp\n# use parameters from above: PReFit\n\n\n# create parameters\nPsObs <- cbind(calibrationData[[calibID[gp]]]$data[1,\"xObserved\"],\n               calibrationData[[calibID[gp]]]$data[1,\"yObserved\"],\n               PReFit)\n\n# simulate observations\nsimObs <- runSimulation(environment = HSvals, \n                        iterations = 40000, \n                        PsObs, \n                        randomSeed = NULL,\n                        \"observed\", \n                        TimeAtObservation = calibrationData[[calibID[gp]]]$data[, \"timestamp\"],\n                        maxDuration = NULL,\n                        upperleft = calibrationExtent[c(1,4)],\n                        environmentResolution = 20,\n                        calibrationData[[calibID[gp]]]$startTime,\n                        calibrationData[[calibID[gp]]]$startDoy,\n                        calibrationData[[calibID[gp]]]$centroid[2],\n                        calibrationData[[calibID[gp]]]$centroid[1])\n\nnames(simObs[[1]]) <- paste0(\"reFit_\",seq.int(length(simObs[[1]])))\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n# load simulations\nload(\"../data/simulation.RData\")\n\n# reorder simulation output\nsimOut <- simulation; rm(simulation)\nsimOut$summaries <- list(simOut$summaries[[gp]]) # here 1 = gp\nsimOut$observations <- simObs[[1]]\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n\n#  manual summary selection, take chuncks from LOSim::abcCreateSummaries\n\n# number of available cores for parallelisation of ranger random forest\nnCPU = 4\n\n# compute summary statistics for simulated observations\nssSimObs <- getSumStats(simulations = simOut$observations, \n                        sampleSize = 5000, \n                        sumStats = sumStats)\n\n# don't select any summary statistics + choose target parameters\nsummarySelection = 1:NCOL(simOut$summaries[[1]])\ntargetParameters = c(1,2,4,8)\n\ntempSum = simOut$summaries[[1]]\ntempSum[is.na( tempSum)] = 0\n\nsimObsPreds <- vector(\"list\", n)\nrfsummaries <- vector(\"list\", length(targetParameters))\nsimRFPreds <- as.data.frame(matrix(0, ncol = length(targetParameters), nrow = NROW(tempSum)))\ncolnames(simRFPreds) <- paste0(\"S\", seq_along(targetParameters))\nsimObsRFPreds <- as.data.frame(matrix(0, ncol = length(targetParameters), nrow = n))\ncolnames(simObsRFPreds) <- paste0(\"S\", seq_along(targetParameters))\n\nindex = 1\nfor(j in targetParameters){\n  if(predictionPredictor){\n    TrainData <- data.frame(y = simOut$parameters[,j], \n                            tempSum[,summarySelection], \n                            simRFPreds)\n  }else{\n    TrainData <- data.frame(y = simOut$parameters[,j], \n                            tempSum[,summarySelection])\n  }\n  \n  rfsummaries[[index]] <- ranger::ranger(y ~ ., data = TrainData, \n                                         num.trees = 500, write.forest = TRUE, \n                                         num.threads = nCPU, verbose = FALSE,\n                                         importance =  \"impurity\")\n  \n  simRFPreds[,index] <- predict(rfsummaries[[index]], data = TrainData, num.threads = nCPU)$predictions\n  \n  # predict for simulated observations\n  for(t in seq(NROW(ssSimObs[[1]]))){\n    if(predictionPredictor){\n      PredSimObs <- as.data.frame(matrix(c(ssSimObs[[1]][t, summarySelection], \n                                           simObsRFPreds[t,]), nrow = 1))\n    }else{\n      PredSimObs <- as.data.frame(matrix(ssSimObs[[1]][t, summarySelection], nrow = 1))\n    }\n    \n    colnames(PredSimObs) <- colnames(TrainData)[-1]\n    simObsRFPreds[t,index] <- predict(rfsummaries[[index]], data = PredSimObs, num.threads = nCPU)$predictions\n  }\n  cat(\"targetParameter\",targetParameters[index], \"\\n\")\n  index <- index + 1\n}\n\n# re-organise output\nfor(t in seq(NROW(ssSimObs[[1]]))){\n  simObsPreds[[t]] <- simObsRFPreds[t,]\n}\n\n\n# collect results\n# simOut$summarySelection$predict = predict\nsimOut$summarySelection$predictionPredictor = predictionPredictor\nsimOut$summarySelection$simulation = simRFPreds\nsimOut$summarySelection$observed = simObsPreds\nsimOut$summarySelection$method = \"rF\"\nsimOut$summarySelection$targetParameters = targetParameters\nsimOut$summarySelection$summarySelection = summarySelection\n\n# save(simOut, file = \"../data/simObs_ParameterReFit.RData\")\n# load(\"../data/simObs_ParameterReFit.RData\")\n\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n# copy simulations \nsimOut$summarySelection$simulation <- lapply(seq(n), function(x) simOut$summarySelection$simulation)\n# rejection\nposteriorOutS <- getEstimate(simOut, proportionFiltered = proportionFiltered, \n                             parallel = FALSE, regr.adj = regr.adj, comp.MAP = comp.MAP)\n\n# save(posteriorOutS, file = \"../data/posteriorOutS_ParameterReFit.RData\")\n# load(\"../data/posteriorOutS_ParameterReFit.RData\")\n\n# save all in one file\nsave(posteriorInS,\n     posteriorOutS,\n     PReFit,\n     Pwhich, file = \"../data/parameterReFit.RData\")\n# load(\"../data/parameterReFit.RData\")\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n\n# plot for in sample\n# real vs. fitted\n\nplotParameterReFit <- function(posteriorObj, parameterNames, truePar, \n                               plotMedian = FALSE, plotMAP = TRUE, idLine = TRUE, ...){\n  # edit par\n  par(...)\n  \n  for(p in parameterNames){\n    plot(1:3, type = \"n\", xlim = range(truePar[,p]), \n         ylim = range(truePar[,p]), ylab = paste(\"est.\",p), xlab = paste(\"true\",p))\n    # 95% CI as line\n    for(i in 1:NROW(truePar)) lines(rep(truePar[i,p],2), \n                                    posteriorObj$quantiles[[i]][,p], col = rgb(.5,.5,.5,.5))\n    if(plotMedian){\n      # median as point\n      for(i in 1:NROW(truePar)) points(truePar[i,p], \n                                       posteriorObj$median[[i]][p], cex = 0.5,pch = 16) \n    }\n    if(plotMAP){\n      # median as point\n      for(i in 1:NROW(truePar)) points(truePar[i,p], \n                                       posteriorObj$MAP[[i]][p], cex = 0.5,pch = 16) \n    }\n    if(idLine) abline(0,1, col = 2, xpd = FALSE)\n  }\n}\n\npNames <- c(\"habitatPreference\", \"stepShape\", \"directionalBias\", \"roostLambda\")\npdf(\"../figures/results/refit_rf_inSample.pdf\", width = 10, height = 10)\nplotParameterReFit(posteriorInS, pNames, PReFit, plotMedian = FALSE, plotMAP = TRUE, idLine = TRUE, \n                   mfrow = c(2,2), pty = \"s\", mar = c(2,1,1,1), oma = c(1,1.5,0,0), las = 1, \n                   mgp = c(1.7,0.2,0), tcl = .2, cex.axis = 1.2, cex.lab = 1.2, xpd = NA)\ndev.off()\n\npdf(\"../figures/results/refit_rf_outSample.pdf\", width = 10, height = 10)\nplotParameterReFit(posteriorOutS, pNames, PReFit, plotMedian = FALSE, plotMAP = TRUE, idLine = TRUE, \n                   mfrow = c(2,2), pty = \"s\", mar = c(2,1,1,1), oma = c(1,1.5,0,0), las = 1, \n                   mgp = c(1.7,0.2,0), tcl = .2, cex.axis = 1.2, cex.lab = 1.2, xpd = NA)\ndev.off()\n\n\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n\n# plot for out of sample\n# real vs. fitted\n# \n# x11(10,10)\n# par(mfrow=c(2,2), pty = \"s\")\n# # habitat preference\n# plot(PReFit[,\"habitatPreference\"], sapply(1:500, function(x) posteriorOutS$median[[x]][\"habitatPreference\"]))\n# # habitat preference\n# plot(PReFit[,\"stepShape\"], sapply(1:500, function(x) posteriorOutS$median[[x]][\"stepShape\"]))\n# # habitat preference\n# plot(PReFit[,\"directionalBias\"], sapply(1:500, function(x) posteriorOutS$median[[x]][\"directionalBias\"]))\n# # habitat preference\n# plot(PReFit[,\"roostLambda\"], sapply(1:500, function(x) posteriorOutS$median[[x]][\"roostLambda\"]))\n\n\n\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##\n#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##",
    "created" : 1503580396465.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "313829047",
    "id" : "17315F6B",
    "lastKnownWriteTime" : 1504855811,
    "last_content_update" : 1504870741768,
    "path" : "~/Documents/Uni/projects/littleowl/code/ParameterReFit.r",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}